{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NBA League Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a list of URLs for each player in the NBA, and we want to scrape the per game stats for each player\n",
    "#we want to create a function that takes in a URL and returns a dataframe of the per game stats for that player\n",
    "def get_per_season_stats_e(link):    \n",
    "    res = requests.get(link)\n",
    "    #the code that could potentially have an error is put in a try clause; the program execution moves to the start of a following except clause if an error happens\n",
    "    try:\n",
    "        res.raise_for_status()\n",
    "    except Exception as exc:\n",
    "        print('There was a problem: %s' % (exc))\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    per_season_stats = soup.find('div', class_ = 'table_wrapper', id = 'all_confs_standings_E')\n",
    "        #soup.find('table', class_ = 'stats_table', id = 'per_game')\n",
    "        #find_all() method returns a list of Tag objects, which is how Beautiful Soup represents an HTML element\n",
    "        #iterate through all teams and grab their stats\n",
    "    per_season_stats_by_team = per_season_stats.find_all('tr', class_ = 'full_table')\n",
    "    team_name = []\n",
    "    wins = []\n",
    "    losses = []\n",
    "    win_loss_pct = []\n",
    "    for i in per_season_stats_by_team:\n",
    "        #grab team name and stats for each team\n",
    "        team_name.append(i.find_all('th', class_ = 'left')[0].find('a').text)\n",
    "        wins.append(i.find_all('td')[0].text)\n",
    "        losses.append(i.find_all('td')[1].text)\n",
    "        win_loss_pct.append(i.find_all('td')[2].text)  \n",
    "    #grab season number\n",
    "    season_number = soup.find('h1').find('span').text    \n",
    "    #grab conference\n",
    "    conference = soup.find('div', class_ = 'table_wrapper', id = \"all_confs_standings_E\").find('th').text\n",
    "    #grab league winner\n",
    "    league_champions = soup.find('div', id = 'meta').find_all('div')[1].find('p').find('a').text\n",
    "    #create dataframe\n",
    "    df = pd.DataFrame(zip(team_name, wins, losses, win_loss_pct), columns = ['team_name', 'wins', 'losses', 'win_loss_pct'])\n",
    "    #add season number column\n",
    "    df['season_number'] = season_number\n",
    "    #add conference column\n",
    "    df['conference'] = conference\n",
    "    #add league champion column\n",
    "    df['league_champions'] = league_champions\n",
    "    #append western conference dataframe to eastern conference dataframe    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a list of URLs for each player in the NBA, and we want to scrape the per game stats for each player\n",
    "#we want to create a function that takes in a URL and returns a dataframe of the per game stats for that player\n",
    "def get_per_season_stats_w(link):    \n",
    "    res = requests.get(link)\n",
    "    #the code that could potentially have an error is put in a try clause; the program execution moves to the start of a following except clause if an error happens\n",
    "    try:\n",
    "        res.raise_for_status()\n",
    "    except Exception as exc:\n",
    "        print('There was a problem: %s' % (exc))\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    per_season_stats = soup.find('div', class_ = 'table_wrapper', id = 'all_confs_standings_W')\n",
    "        #soup.find('table', class_ = 'stats_table', id = 'per_game')\n",
    "        #find_all() method returns a list of Tag objects, which is how Beautiful Soup represents an HTML element\n",
    "        #iterate through all teams and grab their stats\n",
    "    per_season_stats_by_team = per_season_stats.find_all('tr', class_ = 'full_table')\n",
    "    team_name = []\n",
    "    wins = []\n",
    "    losses = []\n",
    "    win_loss_pct = []\n",
    "    for i in per_season_stats_by_team:\n",
    "        #grab team name and stats for each team\n",
    "        team_name.append(i.find_all('th', class_ = 'left')[0].find('a').text)\n",
    "        wins.append(i.find_all('td')[0].text)\n",
    "        losses.append(i.find_all('td')[1].text)\n",
    "        win_loss_pct.append(i.find_all('td')[2].text)  \n",
    "    #grab season number\n",
    "    season_number = soup.find('h1').find('span').text    \n",
    "    #grab conference\n",
    "    conference = soup.find('div', class_ = 'table_wrapper', id = \"all_confs_standings_W\").find('th').text\n",
    "    #grab league winner\n",
    "    league_champions = soup.find('div', id = 'meta').find_all('div')[1].find('p').find('a').text\n",
    "    #create dataframe\n",
    "    df = pd.DataFrame(zip(team_name, wins, losses, win_loss_pct), columns = ['team_name', 'wins', 'losses', 'win_loss_pct'])\n",
    "    #add season number column\n",
    "    df['season_number'] = season_number\n",
    "    #add conference column\n",
    "    df['conference'] = conference\n",
    "    #add league champion column\n",
    "    df['league_champions'] = league_champions\n",
    "    #append western conference dataframe to eastern conference dataframe    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to grab stats from multiple URLs\n",
    "def get_per_season_stats_multiple_links(links):\n",
    "    df_list = []\n",
    "    for i in links:\n",
    "        df_list.append(get_per_season_stats_e(i))\n",
    "        df_list.append(get_per_season_stats_w(i))\n",
    "    df = pd.concat(df_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_per_season_stats_multiple_links(['https://www.basketball-reference.com/leagues/NBA_2023.html'\n",
    "                                    ,'https://www.basketball-reference.com/leagues/NBA_2022.html'\n",
    "                                    ,'https://www.basketball-reference.com/leagues/NBA_2021.html'\n",
    "                                    ,'https://www.basketball-reference.com/leagues/NBA_2020.html'\n",
    "                                    ,'https://www.basketball-reference.com/leagues/NBA_2019.html'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('nba_season_stats.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Off to Looker Studio!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
